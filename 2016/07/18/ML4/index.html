<!doctype html>



  


<html class="theme-next pisces use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  
    
      
    

    
  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|Bree Serif:300,300italic,400,400italic,700,700italic|Arimo:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Coursera,Machine Learning," />








  <link rel="shortcut icon" type="image/x-icon" href="/images/sushi.png?v=5.0.1" />






<meta name="description">
<meta property="og:type" content="article">
<meta property="og:title" content="[Completed] Coursera: Machine Learning by Stanford - Part4">
<meta property="og:url" content="http://www.xuyiruan.com/2016/07/18/ML4/index.html">
<meta property="og:site_name" content="阮先生de小窝">
<meta property="og:description">
<meta property="og:image" content="https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera.s3.amazonaws.com/topics/ml/large-icon.png">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160814/high-variance.png">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160814/gradient-descent.png">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160814/quiz.png">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160814/smaller-learning-rate.png">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160814/larger-average-sample.png">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160814/flat-curve.png">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160814/increaseing.png">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160814/map-reduce.png">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160814/map-reduce-on-batch-gradient-descent.png">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160814/MULTIPLE-CORE.png">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160815/photo-ocr.png">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160815/ocr-example.png">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160815/photo-ocr-pipline.png">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160815/pedistrian-detection.png">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160815/pedistrian-detect-small.gif">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160815/pedistrian-detect-large.gif">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160815/text-detect-expansion.png">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160815/sliding-window-segmentation.gif">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160815/synthetic-data-photo-ocr.png">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160815/artificial-warping.png">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160815/ceiling-analysis.png">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160815/face-recg-pipline.png">
<meta property="og:image" content="http://7xihzu.com1.z0.glb.clouddn.com/20160815/certificate.png">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="[Completed] Coursera: Machine Learning by Stanford - Part4">
<meta name="twitter:description">




<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: 'Author'
    }
  };
</script>

  <title> [Completed] Coursera: Machine Learning by Stanford - Part4 | 阮先生de小窝 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">阮先生de小窝</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">多读书 多思考 少吃零食 多睡觉</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                [Completed] Coursera: Machine Learning by Stanford - Part4
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2016-07-18T10:15:48-04:00" content="07-18-2016">
              07-18-2016
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/07/18/ML4/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2016/07/18/ML4/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
             <span id="/2016/07/18/ML4/" class="leancloud_visitors" data-flag-title="[Completed] Coursera: Machine Learning by Stanford - Part4">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">visitors </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><img src="https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera.s3.amazonaws.com/topics/ml/large-icon.png" alt=""></p>
<a id="more"></a>
<h1 id="Week_10:_Lesson_1">Week 10: Lesson 1</h1><h2 id="Gradient_Descent_with_Large_Datasets">Gradient Descent with Large Datasets</h2><h3 id="Learning_With_Large_Datasets"><center> Learning With Large Datasets </center></h3><ul>
<li>alogrithm deal with large data set.  </li>
<li>come up with computational efficient way to deal with large dataset.  </li>
</ul>
<h4 id="Learning_with_large_datasets">Learning with large datasets</h4><ul>
<li>typically with $m=100,000,000$, computational heavy.  </li>
<li>better to try random small subset of $m=1,000$ first.  </li>
<li>plot the learning curve of $J_{cv}(\theta)$ and $J_{train}{\theta}$  v.s. $m$ (training size) will help to better determine if increasing $m$ will likely imporve the learning accuracy. (high variance -&gt; increasing $m$ will likely imporve accuracy).  </li>
</ul>
<p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160814/high-variance.png" alt=""></p>
<h3 id="Stochastic_Gradient_Descent"><center> Stochastic Gradient Descent </center></h3><ul>
<li>gradient escent - computational expensive for large data set.  </li>
<li>to compute gradient descent for large data set $m$, we perfer using stochastic gradient descent.  </li>
<li>batch gradient descent vs. stochastic gradient descent  </li>
<li>instead of getting directly to global minimum, stochastic gradient descent will likely <strong>wondering around</strong> the global minimum.  </li>
</ul>
<h4 id="Gradient_descent">Gradient descent</h4><p>Every iteration approaches directly to the global minimum step by step.<br>However, as $m$ get large(<code>100,000,000</code> scale), every iteration, it needs to go through $m$ number of training sets and it is very heavy computation. It is considered heavy computation because it is memory cant hold up that amount of data at once, and swaping bewteen disk and memory is required.  </p>
<p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160814/gradient-descent.png" alt=""></p>
<p>In case of large training example $m$, we need more efficient algorithm.  </p>
<h4 id="Stochastic_gradient_descent">Stochastic gradient descent</h4><p>We defined:  </p>
$$cost(\theta, (x^{(i)}, y^{(i)})) = \frac{1}{2}(h_{\theta}(x^{(i)})-y^{(i)})^2$$
<p>Similar to Gradient descent, We have:  </p>
$$J_{train}(\theta) = \dfrac{1}{m} \displaystyle \sum_{i=1}^m cost(\theta, (x^{(i)}, y^{(i)}))$$
<p>The only difference was in the <strong>iteration updating step.</strong> Instead of iterating through the <strong>entire</strong> $m$ number of examples to get a <strong>single</strong> update, we update the parameter $\theta$ at <strong>every</strong> training set.  </p>
<h4 id="Stochastic_gradient_algorithm">Stochastic gradient algorithm</h4><ul>
<li>1.Randomly ‘shuffle’ the dataset  </li>
<li>2.For $i=1…m$  </li>
</ul>
$$\Theta_j := \Theta_j - \alpha (h_{\Theta}(x^{(i)}) - y^{(i)}) \cdot x^{(i)}_j$$
<p>$\Theta_j$ now updates for every $(x^{(i)}, y^{(i)})$ pair. With stochastic gradient, we can <strong>make progress</strong> in gradient descent <strong>without</strong> having to scan <strong>all $m$ training set</strong> first.   </p>
<p>Stochastic gradient descent <strong>will not</strong> converge to global minimum, instead, it will wondering <strong>around</strong> the global minimum and result in a solution that is close enough.  </p>
<p>Stochastic gradient descent usually take about $1-10$ passes through your data set to get near the global minimum.  </p>
<p><strong>Quiz:</strong><br><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160814/quiz.png" alt=""></p>
<h3 id="Mini-batch_gradient_descent"><center> Mini-batch gradient descent </center></h3><ul>
<li>mini-batch faster than stochastic gradient descent and batch gradient descent.  </li>
<li>advantage and disadvantage of mini-batch gradient descent.  </li>
</ul>
<h4 id="Mini-batch_gradient_descent-1">Mini-batch gradient descent</h4><ul>
<li>with good choice of parameter $b$, mini-batch sometimes faster than stochastic gradient descent.  </li>
<li>batch gradient descent[$m$ example each iteration]/stochastic gradient descent[$1$ example each iteration], mini-batch gradient descent using $b$ example for each iteration.  </li>
<li>$b\in[2,100]$  </li>
</ul>
<p>For example, with $b=10$ and $m = 1000$:  </p>
<ul>
<li>Repeat:  </li>
<li>for $i = 1,11,21,31,\dots,991:$  </li>
<li>$\theta_j := \theta_j - \alpha \dfrac{1}{10} \displaystyle \sum_{k=i}^{i+9} (h_\theta(x^{(k)}) - y^{(k)})x_j^{(k)}$ (for each $j = 0, \dots, n$)  
</li>
</ul>
<h4 id="Mini-batch_vs_Stochastic_gradient_descent">Mini-batch vs Stochastic gradient descent</h4><p><strong>Advantage</strong>: Vectorization implementation over $b$ examples -&gt; more parallel  </p>
<p><strong>Disadvantage</strong>: extra parameter $b$ to fit.  </p>
<h3 id="Stochastic_Gradient_descent_convergence"><center> Stochastic Gradient descent convergence </center></h3><ul>
<li>choosing learning rate $\alpha$ for stochastic gradient descent  </li>
<li>how to make sure it is converging okay?  </li>
<li>compute and save average cost of hypothesis $cost(\theta, (x^{(i)},y^{(i)}))$ over the last $1000$ examples processed by algorithm.  </li>
<li>possible thing to try out for different situations.  </li>
</ul>
<h4 id="Checking_for_convergence">Checking for convergence</h4><h5 id="Better_precision_at_covergence">Better precision at covergence</h5><p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160814/smaller-learning-rate.png" alt=""></p>
<ul>
<li>red curve: learning algorithm with smaller learning rate $\alpha$. Smaller learning rate $\alpha$, smaller occilscation of stochastic gradient descent around the global minimum.    </li>
</ul>
<h5 id="Plot_too_noisy">Plot too noisy</h5><p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160814/larger-average-sample.png" alt=""></p>
<ul>
<li>red curve: increasing from $1000$ to $5000$, smoother plot</li>
</ul>
<h5 id="Flat_curve(cost_not_decreasing)">Flat curve(cost not decreasing)</h5><p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160814/flat-curve.png" alt=""></p>
<ul>
<li>red curve: increase to average of large sample data (from $1000$ to $5000$). Slowly decreasing  </li>
<li>pink curve: if change to average of large sample data does not help, there might be something wrong with features you choose, etc.  </li>
</ul>
<h5 id="plot_increasing">plot increasing</h5><p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160814/increaseing.png" alt=""></p>
<ul>
<li>try smaller value of learning rate $\alpha$</li>
</ul>
<p>Learning rate $\alpha$ is typically held constant. Can slowly decrease $\alpha$ over time if we want $\theta$ to converge.  </p>
$$\alpha_{new} = \frac{const1}{iterationNumber + const2}$$
<p>As number of iteration (number of training example went through) increase, learning rate $\alpha$ gradually decrease. However, the two parameters $const1$ and $const2$ need extra time to compute. </p>
<h3 id="Online_learning"><center> Online learning </center></h3><ul>
<li>learning continously from the data generated by the user.  </li>
<li>learning example $(x, y)$ and discard that and move on with new coming data set. </li>
</ul>
<h4 id="Online_learning-1">Online learning</h4><p>With a continuous stream of users to a website, we can run an endless loop that gets $(x,y)$, where we collect some user actions for the features in $x$ to predict some behavior $y$.  </p>
<p>You can update $θ$ for each individual $(x,y)$ pair as you collect them. This way, you can adapt to new pools of users, since you are continuously updating theta.   </p>
<h4 id="Other_online_learning_example:">Other online learning example:</h4><ul>
<li>Chossing special offers to show user  </li>
<li>customized selection of news articles  </li>
<li>product reommendation  </li>
</ul>
<h1 id="Week_10:_Lesson_2">Week 10: Lesson 2</h1><h2 id="Map-reduce">Map-reduce</h2><h3 id="Map-reduce_and_data_parallelism"><center> Map-reduce and data parallelism </center></h3><ul>
<li>run computation and data on different machines  </li>
<li>large scale machine learning  </li>
</ul>
<h4 id="Map-reduce_idea">Map-reduce idea</h4><ul>
<li>parallelizing computation accross different machine.  </li>
</ul>
<p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160814/map-reduce.png" alt=""></p>
<h4 id="Map-reduce_on_batch_gradient_descent">Map-reduce on batch gradient descent</h4><p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160814/map-reduce-on-batch-gradient-descent.png" alt=""></p>
<h4 id="Map-reduce_and_summation_over_training_set">Map-reduce and summation over training set</h4><blockquote>
<p>Can every learning algorithm be expressed as the summation of the training set?  </p>
</blockquote>
<p>Many learning algorithms <strong>can</strong> be expressed as computing sums of functions over the training set.  </p>
<p>Your learning algorithm is MapReduceable if it can be expressed as computing <strong>sums</strong> of functions over the training set. Linear regression and logistic regression are easily parallelizable.</p>
<p>For neural networks, you can compute <strong>forward propagation and back propagation</strong> on subsets of your data on many machines. Those machines can report their derivatives back to a ‘master’ server that will combine them.</p>
<h4 id="Single-computer,_multi-core_machines">Single-computer, multi-core machines</h4><p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160814/MULTIPLE-CORE.png" alt=""></p>
<p>Advantage: not need to worry about <strong>network latency</strong>  </p>
<p><strong>Library with multi-core capability:</strong> Some numerical linear algebra library that automatically implament the multi-core techique.  </p>
<h1 id="Week_11:_Lesson_1">Week 11: Lesson 1</h1><h2 id="Photo_OCR">Photo OCR</h2><h3 id="Problem_Description_and_Pipeline"><center> Problem Description and Pipeline </center></h3><ul>
<li>intro to Photo OCR problem  </li>
<li>into to machine learning pipline  </li>
</ul>
<h4 id="Photo_OCR_problem">Photo OCR problem</h4><ul>
<li>recognize text in picture  </li>
</ul>
<p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160815/photo-ocr.png" alt=""></p>
<h4 id="Photo_OCR_pipline">Photo OCR pipline</h4><ul>
<li>1.text detection  </li>
<li>2.character segmentation  </li>
<li>3.character classification  </li>
</ul>
<p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160815/ocr-example.png" alt=""></p>
<p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160815/photo-ocr-pipline.png" alt=""></p>
<h4 id="Machine_learning_pipline">Machine learning pipline</h4><ul>
<li>how to break a big problem into a sequence of different modules  </li>
<li>different team can work seperate to different memeber/team  </li>
</ul>
<h3 id="Sliding_Windows"><center>Sliding Windows </center></h3><ul>
<li>sliding windows classifier  </li>
<li>sliding windows example on pedestrian detection  </li>
<li>sliding windows example on character segmentation  </li>
</ul>
<h4 id="Supervised_learning_for_pedestrain_detection">Supervised learning for pedestrain detection</h4><p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160815/pedistrian-detection.png" alt=""></p>
<p><strong>Terms:</strong></p>
<ul>
<li>step size/stride = the number of pixels that the windows slide accross the image.  </li>
</ul>
<p><strong>Run on a smaller scale windows</strong></p>
<p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160815/pedistrian-detect-small.gif" alt=""></p>
<p><strong>Run on a larger scale windows</strong></p>
<p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160815/pedistrian-detect-large.gif" alt=""></p>
<h4 id="Text_detection_expansion">Text detection expansion</h4><p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160815/text-detect-expansion.png" alt=""></p>
<h4 id="1D_sliding_window_for_character_segmentation">1D sliding window for character segmentation</h4><ul>
<li>supervised learning to find split of characters.  </li>
<li>trained a classifier with neural network, etc.  </li>
</ul>
<p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160815/sliding-window-segmentation.gif" alt=""></p>
<h3 id="Getting_Lots_of_Data_and_Artificial_Data"><center> Getting Lots of Data and Artificial Data </center></h3><ul>
<li>Artificial data: creating new data from scratch  </li>
<li>Amplification: turn small training set into larger one  </li>
</ul>
<h4 id="Artificial_data_synthesis_for_photo_OCR">Artificial data synthesis for photo OCR</h4><ul>
<li>synthetic data: patch character from font library with a random background.  </li>
</ul>
<p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160815/synthetic-data-photo-ocr.png" alt=""></p>
<h4 id="Artificial_data:_amplification">Artificial data: amplification</h4><ul>
<li>take one current example and apply warp and distortion to create new training examples.  </li>
<li>amplify one training example to 16 new training examples  </li>
</ul>
<p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160815/artificial-warping.png" alt=""></p>
<h4 id="Discussion_on_getting_more_data">Discussion on getting more data</h4><ul>
<li>artificial data synthesis (from scratch)  </li>
<li>amplify current examples to 10x of number of examples.  </li>
<li>collect/label it yourself  </li>
<li>“crowd source” (Amazon Mechanical Turk)  </li>
</ul>
<h3 id="Ceiling_Analysis:_What_Part_of_the_Pipeline_to_Work_on_Next"><center> Ceiling Analysis: What Part of the Pipeline to Work on Next </center></h3><ul>
<li>determine what type of pipeline to work and spend most time trying to improve.  </li>
</ul>
<h4 id="Ceiling_analysis">Ceiling analysis</h4><ul>
<li>for all four stages, manually select correct answer to have 100% accuracy for each stages  </li>
<li>see with the 100% accuracy, which stage’s 100% accuracy provide the best improvement to overall accuracy.  </li>
<li>we can later determine which stage to spend time on to improve.  </li>
<li>estimate the upper bound (ceiling) of each stage.  </li>
</ul>
<p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160815/ceiling-analysis.png" alt=""></p>
<h4 id="Ceiling_analysis:_Face_recognition_from_image">Ceiling analysis: Face recognition from image</h4><ul>
<li>more complicated pipeline.  </li>
</ul>
<p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160815/face-recg-pipline.png" alt=""></p>
<ul>
<li>from the ceiling analysis above, we can see that spending 18 months working on background removal will not likely to help improvement of overall accuracy.  </li>
<li>however, working on face detection will make the most overall improvement in this case.  </li>
<li>doing a ceiling analysis before-hand will significant save lots of effort.  </li>
<li>dont waste your time on somthing that is not likely to give significant improvement  </li>
<li>dont trust your gut feeling, use ceiling analysis to prove in a more reliable way.  </li>
</ul>
<h1 id="Week_11:_Lesson_3">Week 11: Lesson 3</h1><h2 id="Summary">Summary</h2><h3 id="Problem_Description_and_Pipeline-1"><center> Problem Description and Pipeline </center></h3><p><img src="http://7xihzu.com1.z0.glb.clouddn.com/20160815/certificate.png" alt=""></p>
<p>Thank you, Andrew Ng!</p>
<h1 id="Logs">Logs</h1><ul>
<li>08/14/2016: Week 10 completed.  </li>
<li>08/15/2016: Course completed.  </li>
</ul>

      
    </div>

    <div>
      
        
      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Coursera/" rel="tag">#Coursera</a>
          
            <a href="/tags/Machine-Learning/" rel="tag">#Machine Learning</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/07/18/ML3/" rel="next" title="[Completed] Coursera: Machine Learning by Stanford - Part3">
                <i class="fa fa-chevron-left"></i> [Completed] Coursera: Machine Learning by Stanford - Part3
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2016/07/18/ML2/" rel="prev" title="[Completed] Coursera: Machine Learning by Stanford - Part2">
                [Completed] Coursera: Machine Learning by Stanford - Part2 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/author.jpg"
               alt="🍣之神" />
          <p class="site-author-name" itemprop="name">🍣之神</p>
          <p class="site-description motion-element" itemprop="description">阮先生’s blog</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">70</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              
                <span class="site-state-item-count">9</span>
                <span class="site-state-item-name">categories</span>
              
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">53</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/ruanxuyi" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.instagram.com/xuyiruan/" target="_blank" title="Instagram">
                  
                    <i class="fa fa-fw fa-instagram"></i>
                  
                  Instagram
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.linkedin.com/in/xuyi-ruan-a728a889" target="_blank" title="Linkedin">
                  
                    <i class="fa fa-fw fa-linkedin"></i>
                  
                  Linkedin
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-block">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://mszhuchinese.com" title="MsZhuChinese" target="_blank">MsZhuChinese</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.winniebabe.com" title="WinnieBabe" target="_blank">WinnieBabe</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://suncuss.me" title="BossSun" target="_blank">BossSun</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Week_10:_Lesson_1"><span class="nav-number">1.</span> <span class="nav-text">Week 10: Lesson 1</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Gradient_Descent_with_Large_Datasets"><span class="nav-number">1.1.</span> <span class="nav-text">Gradient Descent with Large Datasets</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Learning_With_Large_Datasets"><span class="nav-number">1.1.1.</span> <span class="nav-text"> Learning With Large Datasets </span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Learning_with_large_datasets"><span class="nav-number">1.1.1.1.</span> <span class="nav-text">Learning with large datasets</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Stochastic_Gradient_Descent"><span class="nav-number">1.1.2.</span> <span class="nav-text"> Stochastic Gradient Descent </span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Gradient_descent"><span class="nav-number">1.1.2.1.</span> <span class="nav-text">Gradient descent</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Stochastic_gradient_descent"><span class="nav-number">1.1.2.2.</span> <span class="nav-text">Stochastic gradient descent</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Stochastic_gradient_algorithm"><span class="nav-number">1.1.2.3.</span> <span class="nav-text">Stochastic gradient algorithm</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Mini-batch_gradient_descent"><span class="nav-number">1.1.3.</span> <span class="nav-text"> Mini-batch gradient descent </span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Mini-batch_gradient_descent-1"><span class="nav-number">1.1.3.1.</span> <span class="nav-text">Mini-batch gradient descent</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Mini-batch_vs_Stochastic_gradient_descent"><span class="nav-number">1.1.3.2.</span> <span class="nav-text">Mini-batch vs Stochastic gradient descent</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Stochastic_Gradient_descent_convergence"><span class="nav-number">1.1.4.</span> <span class="nav-text"> Stochastic Gradient descent convergence </span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Checking_for_convergence"><span class="nav-number">1.1.4.1.</span> <span class="nav-text">Checking for convergence</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Better_precision_at_covergence"><span class="nav-number">1.1.4.1.1.</span> <span class="nav-text">Better precision at covergence</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Plot_too_noisy"><span class="nav-number">1.1.4.1.2.</span> <span class="nav-text">Plot too noisy</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Flat_curve(cost_not_decreasing)"><span class="nav-number">1.1.4.1.3.</span> <span class="nav-text">Flat curve(cost not decreasing)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#plot_increasing"><span class="nav-number">1.1.4.1.4.</span> <span class="nav-text">plot increasing</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Online_learning"><span class="nav-number">1.1.5.</span> <span class="nav-text"> Online learning </span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Online_learning-1"><span class="nav-number">1.1.5.1.</span> <span class="nav-text">Online learning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Other_online_learning_example:"><span class="nav-number">1.1.5.2.</span> <span class="nav-text">Other online learning example:</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Week_10:_Lesson_2"><span class="nav-number">2.</span> <span class="nav-text">Week 10: Lesson 2</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Map-reduce"><span class="nav-number">2.1.</span> <span class="nav-text">Map-reduce</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Map-reduce_and_data_parallelism"><span class="nav-number">2.1.1.</span> <span class="nav-text"> Map-reduce and data parallelism </span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Map-reduce_idea"><span class="nav-number">2.1.1.1.</span> <span class="nav-text">Map-reduce idea</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Map-reduce_on_batch_gradient_descent"><span class="nav-number">2.1.1.2.</span> <span class="nav-text">Map-reduce on batch gradient descent</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Map-reduce_and_summation_over_training_set"><span class="nav-number">2.1.1.3.</span> <span class="nav-text">Map-reduce and summation over training set</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Single-computer,_multi-core_machines"><span class="nav-number">2.1.1.4.</span> <span class="nav-text">Single-computer, multi-core machines</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Week_11:_Lesson_1"><span class="nav-number">3.</span> <span class="nav-text">Week 11: Lesson 1</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Photo_OCR"><span class="nav-number">3.1.</span> <span class="nav-text">Photo OCR</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Problem_Description_and_Pipeline"><span class="nav-number">3.1.1.</span> <span class="nav-text"> Problem Description and Pipeline </span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Photo_OCR_problem"><span class="nav-number">3.1.1.1.</span> <span class="nav-text">Photo OCR problem</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Photo_OCR_pipline"><span class="nav-number">3.1.1.2.</span> <span class="nav-text">Photo OCR pipline</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Machine_learning_pipline"><span class="nav-number">3.1.1.3.</span> <span class="nav-text">Machine learning pipline</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Sliding_Windows"><span class="nav-number">3.1.2.</span> <span class="nav-text">Sliding Windows </span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Supervised_learning_for_pedestrain_detection"><span class="nav-number">3.1.2.1.</span> <span class="nav-text">Supervised learning for pedestrain detection</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Text_detection_expansion"><span class="nav-number">3.1.2.2.</span> <span class="nav-text">Text detection expansion</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1D_sliding_window_for_character_segmentation"><span class="nav-number">3.1.2.3.</span> <span class="nav-text">1D sliding window for character segmentation</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Getting_Lots_of_Data_and_Artificial_Data"><span class="nav-number">3.1.3.</span> <span class="nav-text"> Getting Lots of Data and Artificial Data </span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Artificial_data_synthesis_for_photo_OCR"><span class="nav-number">3.1.3.1.</span> <span class="nav-text">Artificial data synthesis for photo OCR</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Artificial_data:_amplification"><span class="nav-number">3.1.3.2.</span> <span class="nav-text">Artificial data: amplification</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Discussion_on_getting_more_data"><span class="nav-number">3.1.3.3.</span> <span class="nav-text">Discussion on getting more data</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Ceiling_Analysis:_What_Part_of_the_Pipeline_to_Work_on_Next"><span class="nav-number">3.1.4.</span> <span class="nav-text"> Ceiling Analysis: What Part of the Pipeline to Work on Next </span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Ceiling_analysis"><span class="nav-number">3.1.4.1.</span> <span class="nav-text">Ceiling analysis</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Ceiling_analysis:_Face_recognition_from_image"><span class="nav-number">3.1.4.2.</span> <span class="nav-text">Ceiling analysis: Face recognition from image</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Week_11:_Lesson_3"><span class="nav-number">4.</span> <span class="nav-text">Week 11: Lesson 3</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Summary"><span class="nav-number">4.1.</span> <span class="nav-text">Summary</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Problem_Description_and_Pipeline-1"><span class="nav-number">4.1.1.</span> <span class="nav-text"> Problem Description and Pipeline </span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Logs"><span class="nav-number">5.</span> <span class="nav-text">Logs</span></a></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2015 - 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">🍣之神</span>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="http://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.0.1"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  

    <script type="text/javascript">
      var disqus_shortname = 'xruan';
      var disqus_identifier = '2016/07/18/ML4/';
      var disqus_title = "[Completed] Coursera: Machine Learning by Stanford - Part4";
      var disqus_url = 'http://www.xuyiruan.com/2016/07/18/ML4/';

      function run_disqus_script(disqus_script){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      }

      run_disqus_script('count.js');
      
        run_disqus_script('embed.js');
      
    </script>
  




  
  
  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("oKoPG1XTXkC7T1oasGQwau2g-gzGzoHsz", "JFJCQtIsUKhrX6S7Gvgqdqgk");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

</body>
</html>
