title: "[Completed] Coursera: Machine Learning by Stanford - Part1"
date: 2016-06-18 15:11:11
tags:
- Coursera
- Machine Learning
---

![](https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera.s3.amazonaws.com/topics/ml/large-icon.png)

<!--more-->

# Week 1: Lesson 3

## Supervise Learning

**Examples:**
- Given email labeled as spam/not spam, learn a spam filter. (classification)
- Given a dataset of patients diagnosed as either having diabetes or not, learn to classify new patients as having diabtetes or not. (classification)
- Given data of different house types (room, square feet, year built, wood/concrete.. etc) with their corresponding price, evaluate/preidct the price of a given house. (Regression)

### Regression:  
- predict value according to the data set.  
- predict **continuous valued** output(price)  

### Classification:  
- **discrete valued** output(0 or 1).

### SVM(Support Vector Machine):  
- process of infinte number of features.   



## Unsupervised Learning
**Defination:**   
- did not telling the algorithm how to categorize data sets into different types in advance.  
- automatically find structure/categories on given data sets.  

### Cluster Learning: 
**Examples:**  
- Given a set of news articles found on the web, group them into set of articles about the same story. (Cluster) 
![](http://7xihzu.com1.z0.glb.clouddn.com/20160620/news.png)

- automatically analyzes data sets and group them into different type of genes sequence for diffrent group of individuals' data set. (Cluster)
![](http://7xihzu.com1.z0.glb.clouddn.com/20160620/genes.png)

**Applications:**  
- Market Segementation:  algorithm automatically categorizes customers into different clusters according to customers' data, which make marketing and advertisement more effecients and effecitve.   (Airline company tries to categorizes their frequent flyers to different types to better advertises products for different type of frequent flyiers [YMMV - different people get different targeted advertisement])

![](http://7xihzu.com1.z0.glb.clouddn.com/20160620/market.png)

### Cocktail Party Problem Algorithm

- seperate overlaped audio and let `cocktail party algorithm` to seperate them into different audios tracks.  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160620/cocktail.png)

# Week 1: Lesson 5

## Model Representation

- m = Number of training examples 
- x's = "input" variable/ feature
- y's = "output" variable / target variable
- (x,y) = one training example.
- (x<sup>i</sup> , y<sup>i</sup>) = i<sup>th</sup> training example.  

Traning set -> Learning Algorithm -> h(hypothesis) -> 

> h(hypothesis) - a function that maps from x's -> y's. 

	size of house -> h -> estimated price
	
### Univariate Linear Regression
- Linear Regression with **one variable**. (x)
![](http://7xihzu.com1.z0.glb.clouddn.com/20160620/univariate-linear-regression.png)


## Cost Function
- fit the best straigt line to our data  

Given training set and Hypothesis:  h<sub>θ</sub>(x) = θ<sub>0</sub> + θ<sub>1</sub>x  (linear, single variable)  

How to choose θ<sub>i</sub>'s (Paramenters)?  

- choose θ<sub>0</sub>, θ<sub>1</sub> so that h(x) is close to `y` for our training examples`(x,y)`

- minimize {% raw %}$ \frac 1 {2m}\sum_{i=1}^m (h_\theta(x^{(i)})-y^{(i)})^2 ${% endraw %}(m - # training examples)

**Hypothesis Function:**   
{% raw %}
$$h_{\theta}(x)=\theta_0+\theta_1 x$$
{% endraw %}

**Cost Function(Squared error function)**  
{% raw %}
$$J(\theta_0, \theta_1) = \frac 1 {2m} \sum_{i=1}^m (h_\theta(x^{(i)})-y^{(i)})^2$$
{% endraw %}
![](http://7xihzu.com1.z0.glb.clouddn.com/20160620/cost-function.png)


## Cost Fucntion - Intro I
- difference and relation between Hypothesis Function and Cost Function   
- pick a Hypothesis Function ($\theta_0=0$ pick $\theta_1$)  
- Graphically understand the chice of $\theta_1$ affect Hypothesis Function and Cost Function.  

Hypothesis function $h_0(x)$ 
is a funtion of house area $x$ and price of that house.
{% raw %}
$$h_{\theta}(x)=\theta_1 x$$ 
{% endraw %}

Cost function $J(\theta_1)$ is a funciton of $\theta_1$, assuming $\theta_0=0$.



{% raw %}
$$J(\theta_1) = \frac 1 {2m} \sum_{i=1}^m (h_\theta(x^{(i)})-y^{(i)})^2$$
{% endraw %}

### Find $\theta_1$ by minimizing $J(\theta_1)$ (local MIN of $J(\theta_1)$)

![](http://7xihzu.com1.z0.glb.clouddn.com/20160620/theta1.png)

$$ \theta_1 = 1$$

![](http://7xihzu.com1.z0.glb.clouddn.com/20160620/theta2.png)

$$ \theta_1 = 0.5 $$

![](http://7xihzu.com1.z0.glb.clouddn.com/20160620/theta3.png)

$$ \theta_1 = 0 $$ 

In this case, the local min happens at $ \theta_1 = 1$.

## Cost Fucntion - Intro II
- better understanding of the cost function  
- understand contour plots  
- **manually** looking for $\theta_0$ and $\theta1$ pair that minimize the cost function. 


Pick a hypothesis funciton $\theta_0$ and $\theta1$. In this example, we assume $\theta_0\neq0$.

### Cost Function in 3D
![](http://7xihzu.com1.z0.glb.clouddn.com/20160620/cost-function-2para.png)

### Counter Plot

![](http://7xihzu.com1.z0.glb.clouddn.com/20160620/counter-plot1.png)

$$ \theta_0 = 360,\theta_1 = 0 $$

![](http://7xihzu.com1.z0.glb.clouddn.com/20160620/counter-plot2.png)

$$ \theta_0 = 220,\theta_1 = 0.15 $$

# Week 1: Lesson 6

## Gradient Descent
- Gradient Descent - an algorithm to minimize the cost function J and other function.  
- very general algorithm that used a lot in ML.  
- Gradient - downhill as rapidly as possible. (take the steepest slope)   

**Steps**   
1. start with some $ \theta_0 ,\theta_1 $ ($ \theta_0 = 0 ,\theta_1 = 0$)  
2. Keep chaning $ \theta_0 ,\theta_1 $ to reduce $J(\theta_0, \theta_1)$ until it reaches local minimum.  

**Example**

![](http://7xihzu.com1.z0.glb.clouddn.com/20160620/gradient-dec1.png)

Start with a point that is little bit to the right result in a **different path** to another local-minima.  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160620/gradient-dec2.png)


**Algorithm**  
{% raw %}
$$ \theta_i :=\theta_i - \alpha \frac {\partial}{\partial\theta_i} J(\theta_0,\theta_1),(i = 0, i = 1)$$    
{% endraw %} 

$:= $ - assign statement  
$\alpha$ - learning rate (how far each step should go down hill)

**Implementation**
![Simultaneous Update](http://7xihzu.com1.z0.glb.clouddn.com/20160620/sim-update.png)

## Gradient Descent Intuition
- better intuition of Gradient Descent Algorithm.  
- understand the derivative term.  

{% raw %}
$$ \theta_1 :=\theta_1 - \alpha \frac {\partial}{\partial\theta_1} J(\theta_1)$$    
{% endraw %} 

- if $\alpha$ is too small, gradient decent can be slow.   
- if $\alpha$ too large, gradient decent can overshoot the minimum. It may fails to converge.  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160620/gradient-dec-alpha.png)


As we approach a local minimum, the gradient decent will **automatically** take **smaller steps** even with fixed learning rate $\alpha$. 

![](http://7xihzu.com1.z0.glb.clouddn.com/20160620/fix-alpha.png)

Even $\alpha$ is fixed, slope or $\frac {\partial}{\partial\theta_1} J(\theta_1)$ is decreasing. Therefore, the overall term $\alpha \frac {\partial}{\partial\theta_1} J(\theta_1) $ decreases.


## Gradient Descent For Linear Regression
- apply gradient descent algorithm to minimize suqare error cost function (J).  

{% raw %}
$$ \theta_i :=\theta_i - \alpha \frac {\partial}{\partial\theta_i} J(\theta_0,\theta_1),(i = 0, i = 1)$$    
{% endraw %} 

After taking partial derivative: 
![](http://7xihzu.com1.z0.glb.clouddn.com/20160620/partial-derivative.png)

### Gradient Descent Algorithm
{% raw %}
$$ \theta_0 :=\theta_0 - \alpha \frac {1}{m}\sum_{i=1}^m(h_0(x^{(i)}) - y^{(i)}) $$    

$$ \theta_1 :=\theta_1 - \alpha \frac {1}{m}\sum_{i=1}^m(h_0(x^{(i)}) - y^{(i)})*x^{(i)} $$    
{% endraw %} 

> IMPORTANT: $\theta_0$ and $\theta_1$ need to be updated **simultaneously**. 

Using Gradient Descnet Algorithm to find the best Hyphothesis Function.  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160620/best-hyphthesis-func.png)


### "Batch" Gradient Descent Algorithm
- Batch: each step of gradient descent uses **all the training examples/data**.  
- {% raw %}
$$\sum_{i=1}^m (h_\theta(x^{(i)})-y^{(i)})^2$$
{% endraw %}
- m = total # of training examples/data.  


# Week 1: Lesson 7

## Matrices and Vectors

### Matrix:  
- Rectangular array of numbers
- CAP letter for Matrices(A,B,C,X.etc)  


### Vector:
- An n x 1 matrix (only ONE column)  
- Vector is a special type of matrices  
- 1-indexed(in course) vs 0-indexed(more in ML)  
- lower case letter for value, vector (a, b, c, x, etc)  


## Addition and Scalar Multiplicaiton

### Addition  
- only add matrix of **same dimension**  

### Scalar Multication

![](http://7xihzu.com1.z0.glb.clouddn.com/20160621/scalar-multiplication.png)

## Matrix Vector Multiplication
### Definition:   
- number of Column of A(n) has to MATCH # of row of x (n)  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160621/matrix-vector-multi.png)

### Example:  
![](http://7xihzu.com1.z0.glb.clouddn.com/20160621/matrix-vector-multi-ex.png)


### Advantage of using Matrix Multiplication  
- **simplify** the actual code for implementation  
- increase **readiability**  
- more **efficient** to do matrix multiplication(left) than using for-loop(right) in case of large data-set  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160621/matrix-vs-for-loop.png)

### Convert predicting housing price into Matrix Multiplication  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160621/matrix-matrix-multi-application.png)

## Matrix Matrix Multiplication
- how to multiply two matrix together  

### Example  
![](http://7xihzu.com1.z0.glb.clouddn.com/20160621/matrix-matrix-multi.png)  
> **matrix-matrix multiplication** is simply a break down steps of **matrix-vector multiplication**   


### Definition
![](http://7xihzu.com1.z0.glb.clouddn.com/20160621/matrix-matrix-multi-def.png)

> A's column# has to **match** with B's row#. 

### One more example

![](http://7xihzu.com1.z0.glb.clouddn.com/20160621/matrix-matrix-multi-ex2.png)

> TIPs: break down **matrix-matrix multiplication** into many **matrix-vector multiplication** will make your job more easier.  

### Application of M-M-M
- predicting house price again, YES!  
- as before we have four house sizes  
- but now we have THREE **different** hypothesis functions  
- we want to predict house prices base on three different models  
- higly **optimized** linear algrba **library** are able to help us with complicated matrix-matrix-multiplicaiton  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160621/matrix-matrix-multi-application.png)

## Matrix Multiplication Properties
- benefit: pack lots of complication into just on matrix multiplication operation  
- but be aware of the properties of matrix multiplication  

### Commutative  
- Matrix multiplication is NOT commutative  
$$ A\times B\neq B\times A $$ 

### Associative 
- has to match both **dimension** and **values**  
- Matrix multiplication IS associative  

$$ A \times B \times C = A \times (B \times C)$$

### Identity Matrix  
- denoted as $I$(or $I_{n\times n}$)  
- Examples of identity matrices:  
![](http://7xihzu.com1.z0.glb.clouddn.com/20160621/identity-matrix.png)
- Commutative property holds for identity matrix  

For any matrix A, 

{%raw%}
$$A*I_1 = I_2*A = A$$
{%endraw%}

> If A has $m\times n$ dimension -> $I_1$ has $n\times n$ dimension, while $I_2$ has $m\times m$ dimension  

## Inverse and Transpose

- 1 = "identity"  
- not all numbesr have an inverse(ex. 0)  
- how to compute inverse of a matrix  

### Matrix inverse: 
If A is an $m x m$ matrix, and if it has an inverse,  

{%raw%}
$$A*A^{-1} = A^{-1}*A = I$$  
{%endraw%}

### Example 1  
![](http://7xihzu.com1.z0.glb.clouddn.com/20160621/martix-idneitiy-example.png)  

- How to compute that? We use higly optimized software to compute it.  
- not all matrices have inverse. (a 2x2 matrices that has all zeros in it has NO inverse since there is no way to create diagonal 1's(identity) on the result matrices)  
- Matrices that don't have an inverse are "**singular**" or "**degenerate**"   

![singular matrices](http://7xihzu.com1.z0.glb.clouddn.com/20160621/singular.png)

### Matrix Transpose

![](http://7xihzu.com1.z0.glb.clouddn.com/20160621/transpose.png)

### Definition

Let $A$ be an $m\times n$ matrix, and let $B=A^T$. Then $b$ is an $n\times m$ matrix, and {%raw%}$$B_{ij} = A_{ji}$${%endraw%} .  

In example above:  

{%raw%} 
$A_{12} = B_{21} = 2$, and  $A_{22} = B_{22} = 5$
{%endraw%}

> Tips: simply filp the matrices **along the 45 degree line** will result in Matrix Transpose.  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160621/flip-matrix-transpose.png)


# Week 2: Lesson2

## Multivariate Linear Regression
### <center> Mltivariate Linear Regression </center>
- multiple properities/features  
- more useful model  

#### Multiple features
- $n$ = number of features  
- $x^{(i)}$ = input (features) of $i^{th}$ traning example (a column vector n x 1) 
- $x_j^{(i)}$ = value of feature $j$ in $i^{th}$ traning example  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160627%2Fgradient-descent.png)

Example above has **four** features, therefore, $n=4$. Since there are 47 samples/training data, $m=47$. $x^{2}$ indicates the column vector $ \begin{bmatrix}
1046 \\\ 3 \\\ 2 \\\ 40 \\\ \end{bmatrix} $ and the notation $x_2^{2}$ indicates **second** feature(# of bedrooms) from **second** training data.  

#### New Hypothesis function
**Previously:(one feature)**  
{% raw %}
$$h_{\theta}(x)=\theta_0+\theta_1 x$$
{% endraw %}

**Now:(four features)**  
{% raw %}
$$h_{\theta}(x)=\theta_0+\theta_1 x_1+\theta_2 x_2+\theta_3 x_3+\theta_4 x_4$$
{% endraw %}

**Example Hypthesis function:**  
{% raw %}
$$h_{\theta}(x)=80+0.1 x_1+0.01 x_2+3 x_3-2 x_4$$
{% endraw %}

- $80$ - base price  
- $0.1x_1$ - size **added up** by factor of $0.1$ to base price  
- $0.01x_2$ - number of bedrooms **add up** by a lower factor of $0.01$ to base price  
- $3x_3$ - number of floor **add up** by a factor of 3 to base price  
- $-2x_4$ - age of the house **subtract by** factor of 2 on base price  

#### Formal Definition  
{% raw %}
$$h_{\theta}(x)=\theta_0+\theta_1 x_1+\theta_2 x_2+...+\theta_n x_n$$
{% endraw %}

> For convenience of notation, we defined

 $$x_0 = 1$$.  

{% raw %}
$$h_{\theta}(x)=\theta_0 x_0+\theta_1 x_1+\theta_2 x_2+...+\theta_n x_n$$
{% endraw %}

$x = \begin{bmatrix}
x_0 \\\
x_1 \\\
x_2 \\\
... \\\
x_n
\end{bmatrix}$, $\theta = \begin{bmatrix}
\theta_0 \\\
\theta_1 \\\
\theta_2 \\\
... \\\
\theta_n
\end{bmatrix}$, $\theta^T = \begin{bmatrix}
\theta_0, 
\theta_1, 
\theta_2, 
... 
\theta_n
\end{bmatrix}$

Therefore:  

{% raw %}
$$h_{\theta}(x)=\theta_0 x_0+\theta_1 x_1+\theta_2 x_2+...+\theta_n x_n = \theta^T x$$
{% endraw %}

Result of $\theta^T x$ is $[1\times n] [n\times 1]$ = $1\times1$ dimensional (prediction **price** of the house)
### <center> Gradient Descent for Multiple Variables </center>
- automatically fit the paramenter in hypothesis function for **multiple** features.    

{% raw %}
$$ \theta_j :=\theta_j - \alpha \frac {1}{m}\sum_{i=1}^m(h_0(x^{(i)}) - y^{(i)})*x_j^{(i)} $$    
{% endraw %}


{% raw %}
$$ \theta_0 :=\theta_0 - \alpha \frac {1}{m}\sum_{i=1}^m(h_0(x^{(i)}) - y^{(i)})*x_0^{(i)}, where (x_0^{(i)} = 1)$$
$$ \theta_1 :=\theta_1 - \alpha \frac {1}{m}\sum_{i=1}^m(h_0(x^{(i)}) - y^{(i)})*x_1^{(i)} $$ 
$$ \theta_2 :=\theta_2 - \alpha \frac {1}{m}\sum_{i=1}^m(h_0(x^{(i)}) - y^{(i)})*x_2^{(i)} $$  
$$ ... $$

{% endraw %} 

### <center> Gradient Descent in Practice I - Feature Scaling </center>
- go over some practical tricks to make gradient decent work well: feature scaling   
- idea: make sure features are on a **similiar scale**.  
- so that the gradient descent will converge faster  

**Original Scale**  
$x_1 = size(0-2000 feet^2)$  
$x_2 = number of bedrooms(1-5)$  
![](http://7xihzu.com1.z0.glb.clouddn.com/20160627%2Fscale-before.png)

**After Scaling**  

$x_1 = \frac{size(feet^2)}{2000}$  
$x_2 = \frac{number of bedroom}{5}$

![](http://7xihzu.com1.z0.glb.clouddn.com/20160627%2Fscale-after.png)

Gradient Descent with scaling will result in a faster, **direct path** to find the local minimal and converge much faster, why?

> During the gradient descent, depends on $\alpha$ learning rate, $\theta_1$ and $\theta_2$ value will only change in a limited amount ($\alpha$ is small to prevent overshooting). If $\theta_1$ and $\theta_2$ are not on the similar scale, similar amount of value changes will result in $\theta_2$ value wondering around the same location on y-axis, which will result in a slow converge for the gradient descent.  


> Possible Reason: Feature Scaling + Mean Normalization allows updated $X$ values locate in a **similiar** & **smaller** range ( $ -1 < X < 1$ ) instead of un-normalizaed range ($0<x<2000$). The **smaller**&**united** range allow gradient descent to work **better** even with small value of $\alpha$.  



#### Feature Scaling 
Get every featrue into **approximately** a $-1 \leq x_i \leq 1$ range.  

**Examples of Good Scaling:**  
- $0\leq x_1\leq3$  
- $-2\leq x_2\leq0.5$  
**Examples of BAD Scaling:**   
- $-100\leq x_1\leq100$  
- $-0.001\leq x_1\leq0.001$

#### Mean Normalization  
- another techique to enhance feature scaling's perforamnce      
- Replace $x_i$ with {%raw%}$x_i - \mu_i${%endraw%}  
- Help gradient descent converge more **faster** 

{%raw%}
$$x_i = \frac{x_i-\mu_i}{s_i}$$
{%endraw%}

- $\mu_i$ denotes average value of $x_i$ in training set  
- $s_i$ denotes the range $(max - min)$ or standard deviation of traning set  

### <center> Gradient Descent in Practice II - Learning Rate </center>
{% raw %}
$$ \theta_j :=\theta_j - \alpha \frac {\partial}{\partial\theta_j} J(\theta)$$    
{% endraw %} 
- another technique to make gradient descent work well in practice  
- how to make sure gradient descent is working **correctly**  
- how to **choose** learning rate $\alpha$.  

#### Making sure gradient descent work correctly  
- find the best $theta$ value that **minimize** the $J(\theta)$  
- $J(\theta)$ should **decrease** after every iterations  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160627%2Fgradient-descent-decrease.png)

**Manually convergence test:**  Lookinto the graph to check if gradient descent converge.  

**Automatically convergence test:** Declare convergence if $J(\theta)$ decreases by less than $10^{-3}$ in one interation. 

> determine a good threadshold ($10^{-3}$) is sometimes confusing  


#### Possible bugs
- $\alpha$ too large  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160627%2Falpha-too-small.png)  

#### To choose α, try(three-fold)  
$$...,0.001,0.003,0.01,0.03,0.1,0.3,1...$$ 
  
### <center> Features and Polynomial Regression </center>
- **choose** appropriate features  
- **polynomical regression** for complicated, non-linear functions  

#### Definiing new feature
- instead of using the feature provide, we might able to come up with new feature to simplify the gradient descent algorithm  

**Given features:** `frontage & depth` of a house  
**New feature:** `Area` ($Area = frontage\times depth $)

#### Polynomical Regression
- fit complicate data set with more accurate polynomial function  
- derive polynomical regression with **multi-varient linear regression**  
![](http://7xihzu.com1.z0.glb.clouddn.com/20160627%2Fpolynomial-regression.png) 

{%raw%}
$$h_0(x)=\theta_0+\theta_1\times x_1+\theta_2\times x_2+\theta_3 \times x_3 $$ 
$$ h_0(x)= \theta_0+\theta_1\times (size)+\theta_2\times (size)^2+\theta_3 \times (size)^3 $$ 
{%endraw%}  

where  
feature 1: $x_1 = (size)$   
feature 2: $x_2 = (size)^2$  
feature 3: $x_3 = (size)^3$  

**Scale Range of the features**

feature 1: $(size): 1-1000$   
feature 2: $(size)^2: 1-1000,000$  
feature 3: $(size)^3: 1-10^9$ 


#### Choose a feature  
- if you dont want to go into cubic model function ($x^3$)  
- we can use other feature  ($\sqrt{(x)}$)

![](http://7xihzu.com1.z0.glb.clouddn.com/20160627%2Fsqrt-root-feature.png)

# Week 2: Lesson 3 
## Computing Parameters Analytically
### <center>Normal Equation</center>
- so far, we use gradient descent to find optimal $\theta$  
- a **better way** to solve optimal parameter $\theta$  
- solve for $\theta$ analytically  
- **without** iteratively computation (gradient descent)
- **one step** computation for optimal parameter $\theta
$  
- Feature Scaling is **not necessary** in Normal Equation

#### Example  
![](http://7xihzu.com1.z0.glb.clouddn.com/20160627%2Fnormal-equ-example.png)

#### Equation
$$\theta = (X^TX)^{-1}X^Ty$$

![](http://7xihzu.com1.z0.glb.clouddn.com/20160627%2Fx-inverse.png)
> $x_0^i = 1$

Octave: `pinv(x'*x)*x'*y`  

#### Gradient Descent vs Dis-advantage
![](http://7xihzu.com1.z0.glb.clouddn.com/20160627%2Fgradient-desc-vs-normal-equ.png)
> if $n$ number of features is very large ($n \geq 10^6$), it will be better to use gradient descent to aviod the $O(n^3)$ time complexity of normal equation.


### <center>Normal Equation Noninvertibility</center>
- advanced concpet  
- not all the matrices is invertable (ex. singular matrices)  
- what if $X^TX$ is non-invertible? (singular/degenerate) 

#### `pinv` vs `inv` in Octave
- `pinv` sudo inverse  
- `inv` inverse  

> `pinv` will result in a correct value even matrics is not invertible  

#### Case where $X^TX$ is non-invertible
- Redudant features (linearly dependent)  

$x_1$ = size in $feet^2$  
$x_2$ = size in $m^2$  

> if two features ($feet^2$, $m^2$) has linear relation, $X^TX$ cannot be inverted  

- Too many features (e.g. $m \leq n $) 

**Example**:  
traning set ($m = 10$), number of features ($n = 100$)  

> Number of traning set too small(**not enough** data), it is very hard for us to predict the 100 optimal $\theta$ for each of the features.  

**Solution**:  
- **delete** some **features**  
- use **regularization**(cover later)  



# Week 2: Lesson 6
## Octave/Matlab Tutorial
### <center>Basic Operations</center>
`eye(3)`  % 3x3 identity matrix

     1     0     0
     0     1     0
     0     0     1
     
`sum(v, 1)` -> sum column  
`sum(v, 2)` -> sum row  
`size(v, 1)` -> number of rows  
`size(v, 2)` -> number of cols  


### <center>Moving Data Around</center>

#### A(row_index, col_index)

**`A(2,:)`  % get the 2nd row.**   

```matlab
>> A

A =

     1     2   100
     3     4   101
     5     6   102

>> A(2,:)

ans =

     3     4   101
```

**`A(:,2)`  % get the 2nd col**   
```matlab
>> A(:,2)

ans =

     2
     4
     6
```

**`A = [A, [100; 101; 102]];` % append column vector**  



```matlab
A =

     1     2
     3     4
     5     6

>> A = [A, [100; 101; 102]]

A =

     1     2   100
     3     4   101
     5     6   102
```


**`A(:)` % Select all elements as a column vector.**   
```matlab
A(:)

ans =

     1
     3
     5
     2
     4
     6
   100
   101
   102
```


**% Putting data together**
```matlab
>> A = [1 2; 3 4; 5 6]
B = [11 12; 13 14; 15 16] 

A =

     1     2
     3     4
     5     6


B =

    11    12
    13    14
    15    16
```

**concatenating A and B matrices side by side**
```matlab
>> C=[A B]=[A,B]

C =

     1     2    11    12
     3     4    13    14
     5     6    15    16

```

**Concatenating A and B top and bottom**
```matlab
>> C=[A;B]

C =

     1     2
     3     4
     5     6
    11    12
    13    14
    15    16
```


### <center>Computing On Data</center>

**element-wise operation**   
- notations - `.`

```matlab
>> A

A =

     1     2
     3     4
     5     6

>> A .* 2

ans =

     2     4
     6     8
    10    12

>> A .^ 2

ans =

     1     4
     9    16
    25    36
```
**element-wise log/exp/abs**  

```matlab

v =

     1
     2
     3

>> log(v)

ans =

         0
    0.6931
    1.0986

>> exp(v)

ans =

    2.7183
    7.3891
   20.0855

>> abs(v)

ans =

     1
     2
     3
```

**Important**
For square matrices calculation  $A .* A \neq A^2$

```matlab
>> A = [1 2; 3 4]

A =

     1     2
     3     4

>> A .* A

ans =

     1     4
     9    16

>> A^2

ans =

     7    10
    15    22

```

**Find the transpose**

```matlab
>> A

A =

     1     2
     3     4
     5     6

>> A'

ans =

     1     3     5
     2     4     6

```

**Flip matrix up-side-down**

```matlab

C =

     1     2     4
     3     4     5
     5     6     6

>> flipup(C)
Undefined function or variable 'flipup'.
 
Did you mean:
>> flipud(C)

ans =

     5     6     6
     3     4     5
     1     2     4


```
### <center>Plotting Data</center>

```matlab
%% plotting
t = [0:0.01:0.98];
y1 = sin(2*pi*4*t); 
plot(t,y1);
y2 = cos(2*pi*4*t);
hold on;  % "hold off" to turn off
plot(t,y2,'r');
xlabel('time');
ylabel('value');
legend('sin','cos');
title('my plot');
print -dpng 'myPlot.png'
close;           % or,  "close all" to close all figs

```
![](http://7xihzu.com1.z0.glb.clouddn.com/20160627%2FmyPlot.png)

```matlab
>> A = magic(5)

A =

    17    24     1     8    15
    23     5     7    14    16
     4     6    13    20    22
    10    12    19    21     3
    11    18    25     2     9

>> imagesc(A)
>> imagesc(A), colorbar, colormap gray;
>> print -dpng 'colormap.png'
```
![](http://7xihzu.com1.z0.glb.clouddn.com/20160627%2Fcolormap.png)

### <center>Control Statements: for, while, if statement</center>

#### for-loop

```matlab
>> v=zeros(10,1)

v =

     0
     0
     0
     0
     0
     0
     0
     0
     0
     0
     
>> for i=1:10,
v(i) = 2^i;
end;
>> v

v =

           2
           4
           8
          16
          32
          64
         128
         256
         512
        1024

```

#### while-loop

```matlab
i = 1;
while true, 
  v(i) = 999; 
  i = i+1;
  if i == 6,
    break;
  end;
end

```

#### script(function)  
```matlab
% script file calcuate.m

% function calculate has 
% one input - x 
% two ouputs - y1 & y2
function [y1, y2] = calculate(x)

y1 = x^2;
y2 = x^3;


```

Terminal

```matlab
>> [a, b] = calculate(5)

a =

    25


b =

   125

>> 
```

#### Cost function J example

![](http://7xihzu.com1.z0.glb.clouddn.com/20160627%2Fcost-function-j.png)

### <center>Vectorization</center>
- take advantage of linear algrba library  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160627%2Fvect-example.png)

#### unvectorized implementation
```matlab
prediction = 0.0;
for j = 1:n+1,
	prediction = prediction + theta(j) * x(j)
end;

```
#### Vectorized implementation
```matlab
prediction = theta' * x;
```

#### Gradient descent  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160627%2Fgradient-descent.png)

**Vectorized Implementation**

```matlab

function [theta, J_history] = gradientDescent(X, y, theta, alpha, num_iters)
%GRADIENTDESCENT Performs gradient descent to learn theta
%   theta = GRADIENTDESENT(X, y, theta, alpha, num_iters) updates theta by 
%   taking num_iters gradient steps with learning rate alpha

% Initialize some useful values
m = length(y); % number of training examples
J_history = zeros(num_iters, 1);

for iter = 1:num_iters
    tempTheta = zeros(size(theta, 1) , 1);
    for i = 1: size(tempTheta, 1),
        DiffVector = X * theta - y; % 97 * 1 vector // VECTORIZATION
        sum = X(:,i)' * DiffVector; % 1 x 97 times 97 x 1 = 1 x 1 (sum) // VECTORIZATION
        tempTheta(i) = theta(i) - alpha * (1/m) * sum;
    end
    theta = tempTheta;

    % Save the cost J in every iteration    
    J_history(iter) = computeCost(X, y, theta);

end

end
```

# Week 3: Lesson 1
## <center>Classification and Representation</center>
### Classification
- introduce logistic regression  
- classification problem  
- start with 2 classes classification (binary classification)  

#### Classification Example: 
- email: spam/not spam  
- online transaction: fraudulent(yes/no)  

$$ y \in 0, 1 $$  

#### Linear Regression to do Classification problem 

![](http://7xihzu.com1.z0.glb.clouddn.com/20160628/linear-regression-classification.png)  
- in this particular example, linear regression method is actually doing something reasonable  


![](http://7xihzu.com1.z0.glb.clouddn.com/20160628/linear-regression-bad-example.png)
- as we add one more data point to the right, the hypothesis function become smaller slope, two data points previous classify as malignant(y = 1) now become non-malignant.    
- in most of case, linear regression is not the best approach for classification problem  
- in example above, we might **manually** change the hypothesis function to {%raw%}$h_\theta(x) = 0.3x${%endraw%}. However, if we added one more data point, we will need to **manually** assigned a **different** **slope** for the hypothesis function. We need to find **something else** smarter (evenly seperate using the $h_\theta(x) = 0.5 $ threshold for classification problem). With new approch, even more data points invovole, the alorithm can automatically update the $\theta$ values to make the hypothesis function sucessfully classify the traning sets)  


#### Logistic Regression: 
- an classification algorithm  

$$0\leq h_\theta(x) \leq 1$$
 
### Hypothesis Representation
- output value between 0 and 1 $$0\leq h_\theta(x) \leq 1$$  

#### Logistic Regression Model  
- want $0\leq h_\theta(x) \leq 1$   

#### Sigmoid function/Logistic Function  
$g(z)$ is called Sigmoid function/Logistic function  
$$h_\theta(x) = g(\theta^Tx) , where$$
$$g(z) = \frac{1}{1+e^{-z}}$$

![](http://7xihzu.com1.z0.glb.clouddn.com/20160628/sigmoid-function.png)

$$h_\theta(x) = \frac{1}{1+e^{-\theta^Tx}}$$

#### Interpretation of Hypothesis Output  
- $h_\theta(x) $ = estimated probability that $y=1$ on input x  


$H_\theta(x) = P(y=1|x;\theta)$ reads the probability of $y=1$ given patient with feature $x$, parameterized by $\theta$. 

### Decision Boundary
- virtualization 
- better sense of Logistic regression  

#### logistic regression  
![](http://7xihzu.com1.z0.glb.clouddn.com/20160628/logistic-regression.png)
{%raw%}
$g(z) \geq 0.5$ when $z \geq 0$, since $h_\theta(x) = g(\theta^Tx)$, therefore, $h_\theta(x) \geq 0.5$ where $\theta^Tx \geq 0 $
{%endraw%}

Similarly, $h_\theta(x) < 0.5$ where $\theta^Tx < 0 $


#### Decision Boundary Vitualizaiton  
- once $\theta$ value fixed, the line for decision boundary was also fixed  
- data points from one side of the decision boundary will result in a different `y values` from data points from the other side of the decision boundary  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160628/decision-boundary.png)

#### Non-linear decision boundaries
- decision boundary is **non-linear**  
- we can add **higher order polynomial terms** into the logistic regression  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160628/non-linear-logistic-regression.png)

- decision boundary is determined by the **parameter of the hypothesis** function, not the **traning set**. 
- Traning set is used to determine a better set of $\theta$ values, once $\theta$ values are set, decision boundary is fixed.  


# Week 3: Lesson 2
## Logistic Regression Model  

### Cost Function
- how do we choose $\theta$  

For `Linear Regression`: 

{% raw %}
$$J(\theta) = \frac 1 {m} \sum_{i=1}^m \frac{1}{2}(h_\theta(x^{(i)})-y^{(i)})^2$$
{% endraw %}

However, for cost function for `Logistic Regression`, we might not be able to utilize the same function since the cost function (with $h_{\theta}(x)$ being a sigmoid function) will result in a non-covex fucntion.  

> Non-convex function: function that is not able to converge to a local minium.  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160701/convex.png)  
![](http://7xihzu.com1.z0.glb.clouddn.com/20160701/non-convex.png)  

Therefore, we need to come up with **new** cost function, that does come up into a **convex** function. (so that the fucntion can converge to a local/global minimum).  

#### Logistic regression cost function  

{%raw%}
$$Cost(h_\theta(x),y) = 
\left\{\begin{matrix}
 -log(h_\theta(x)) \; if\;y=1 \\ 
 -log(1-h_\theta(x))\; if \;y = 0 
\end{matrix}\right.$$
{%endraw%}


![](http://7xihzu.com1.z0.glb.clouddn.com/20160701/cost-function-y1.png)

![](http://7xihzu.com1.z0.glb.clouddn.com/20160701/cost-function-y0.png)


### Simplified Cost Function and Gradient Descent  
- simpler way to write out cost fucntion  
- apply gradient descent to get the best $\theta$ values.  


#### Logistic regression cost function  

{% raw %}
$$J(\theta) = \frac 1 {m} \sum_{i=1}^m Cost(h_\theta(x^{(i)}), y^{(i)})$$


$$Cost(h_\theta(x),y) = 
\left\{\begin{matrix}
 -log(h_\theta(x)) \; if\;y=1 \\ 
 -log(1-h_\theta(x))\; if \;y = 0 
\end{matrix}\right.$$

Compressed version for cost function  


$$Cost(h_\theta(x),y) = 
 -y\;log(h_\theta(x)) 
 -(1-y	)log(1-h_\theta(x))$$

{% endraw %}

![](http://7xihzu.com1.z0.glb.clouddn.com/20160701/logistic-regression-cost-function.png)
Above is the compact version of our cost fucntion for logistic regression.  

> Why would we choose this partitular `log` fucntion as cost fucntion is because this function was proven that **provide efficiency** to find $\theta$ values and the most **convex feature** for logistic regression.  


#### Find the theta values that minimize the cost function 

$$\min_{\theta} J(\theta)$$

**Hypothesis Function**  

$$h_\theta(x) = \frac{1}{1+e^{-\theta^{T}x}}$$

the output of the hypothesis function $h_\theta$ indicates   
$$P(y=1\; | \; x;\theta)$$
the **probability** of result being `y=1` with given `x` values (from user) and $\theta$ values (pre-set by gradient descent).  


#### Gradient Descent  



**Update Rules**:  
{% raw %}
$$ \theta_j :=\theta_j - \alpha \frac {\partial}{\partial\theta_j} J(\theta)$$    
{% endraw %} 

{% raw %}
$$ \theta_j :=\theta_j - \alpha \sum_{i=1}^m(h_0(x^{(i)}) - y^{(i)})*x_j^{(i)} $$    
{% endraw %}

Gradient Descent for logistic regression looks exactly **identical** to linear reagression. However, $h_\theta$ function is different.  

$$h_\theta(x) = \frac{1}{1+e^{-\theta^{T}x }}$$

Performing the gradient descent for each of the features $\theta$ and then performing the simultaaneously update all $\theta$ values.  

> $\theta_j$ could be $\theta_0$, $\theta_1$, $\theta_2$... etc  

Instead of using a **for-loop** to update all the $\theta$ values for all features, using **vectorization multiplication** will be more efficient.  


### Advanced Optimization 
- advacned optimzation concept  


#### List of optimzation algorithms: (to minimize the cost fucntion)  
- gradient descent  
- conjugate gradient  
- BFGS  
- L-BFGS  

**Advantages** of the other three alogrithms:  
- **no** need to **maually** pick $\alpha$  
- often **faster** than gradient descent    


**Disadvantages**:  
- more complex  

**Example**:   

Cost function

![](http://7xihzu.com1.z0.glb.clouddn.com/20160701/cost-function0.png)
![](http://7xihzu.com1.z0.glb.clouddn.com/20160701/cost-function.png)  

Instead of manually choose learning rate $\alpha$, we will used advanced optimzation library to automatically use the best learning rate $\alpha$ to find optimal $\theta$ values.  

#### fminunc function  
![](http://7xihzu.com1.z0.glb.clouddn.com/20160701/fminunc.png)  

#### Application of advanced optimzation library to logistic regression  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160701/logistic-regression-with-advanced-optimzation-algorithm.png)


#### Summary: 
**benefit** of using advanced optimzation algorith library
- harder to debug  
- but faster  
- **large** machine learning **problem** will benefit  

# Week 3: Lesson 3
## Multiclass Classification
### Multiclass Classification: One-vs-all
- how to get logistic regression to work for multiclass classification problems.  
- one-versus-all classification  

#### Multiclass classification examples 
- email classification: work, friends, family, hobby  
- weather: sunny, cloudy, rain, snow  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160703/multi-class-classification.png)

#### One-vs-all Example (One-vs-rest)  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160703/one-vs-all-classifcation.png)
- in example above, we come up with **three classifiers**  
- each of which was trained to recognize one of three classes  

#### One-vs-all Definition

Train a logistic regression classifier $h_\theta^{i}(x)$ for each class $i$ to predict the **probability** that $y=i$.  

On a new input $x$, to make a prediction, pick the class $i$ that maximizes 
{%raw%}
$$\max_{i} h_\theta^{(i)}(x)$$  
{%endraw%}

> maxmizes since $h_\theta^{(i)}(x)$ is the probability of class is $i$ given $x$ value.  


## Solving the Problem of Overfitting
### The Problem of Overfitting  
- definition of overfitting  
- regularization: technique to reduce overfitting problem  

#### What is overfitting?  
![](http://7xihzu.com1.z0.glb.clouddn.com/20160703/over-fitting.png)

> **Overfitting:**   
> if we have too many features, the learned hypothesis may **fit** the **trainng set very well**. However, it fails to **generalize** well to make accurate predictions on **new, previously unseen examples**. 

We dont have enough data to constrain it to give us a good hypothesis 

> **High variance:**   
> high order polynomial, hypothesis can fit almost any of the function.  

#### Addressing overfitting  
- ploting is a good start  
- but once the number of features are getting larger  
- it is getting harder to plot and visualize the features.  

> If we have **large number of features** and the **training data set** is **limited**, then **overfitting** will become a problem. How can we avoid overfitting?  

#### Options to avoid overfitting    
1.**Reduce** number of features.  
- manually select which features to keep.  
- model selection algorithm (automatically select features)  

2.**Regularization**  
- Keep all features, but **reduce** **magnitude**/**values** of parameters $\theta_j$.  
- works well when we have lots of features, each of which contributes a bit to predicting y. 


### Cost Function
- main intution of how regularization work  
- cost function for regularization  


#### Regularization  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160703/regularization.png)

(penalize some parameters/features with high cost -> features($\theta$ values) will result in smaller values)

Small values for parameters $\theta_0, \theta_1,...,\theta_n$  
- "Simpler" hypothesis (polynomial -> quadratic function)  
- less prone to overfiting  


#### which one/feature to pick to reduce values?  
We basically regularize all features.  

{% raw %}$$J(\theta) =  \frac 1 {2m}[\sum_{i=1}^m (h_\theta(x^{(i)})-y^{(i)})^2 + \lambda \sum_{j=1}^{n}\theta_j^2] $${% endraw %}

{% raw %} $$ \lambda \sum_{j=1}^{n}\theta_j^2 $${% endraw %}

> Note: $\theta_0$ will NOT participate in the regularzation equation.  

is called the regularzation term.  $ \lambda$ is the regularization parameter.  

> Regularization parameter $\lambda$: 
> it control to both  
> 1) fitting the training data set well,   
> and 2) keeping the paramenters small (smaller parameters ~ 0 -> **get rid** of the feature paramenters -> keep hypothesis simple to prevent overfitting)

#### What happen with large $\lambda$ value? 

![](http://7xihzu.com1.z0.glb.clouddn.com/20160703/large-lambda.png)

#### NextTime
- for regularzation to work well, need to choose good $\lambda$ value  
- multi-selection -> automatically choose regulazation parameter $\lambda$.  

### Regularized Linear Regression

#### Gradient Descent
![](http://7xihzu.com1.z0.glb.clouddn.com/20160703/gradient-descent-with-regularization.png)

#### Normal Equation
![](http://7xihzu.com1.z0.glb.clouddn.com/20160703/normal-equation-regularization.png)  

#### Non-invertibility (optional/advanced)  
- using regularization takes care of any non-invertable issue. (if $\lambda$ > 0).  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160703/non-invertable-regularization.png)

#### Summary
- avoid overfitting with **regularized** linear regression  
- next video will talk about **regularized** logistic regression  

### Regularized Logistic Regression
- previously - gradient descent & advanced technique algorithm(automatically choosing learning rate)  

![](http://7xihzu.com1.z0.glb.clouddn.com/20160703/regularized-logistic-regression.png)
- **blue boundary** is the logistic regression **without** regularization  
- **pink boundary** is the logistic regression **with** regularization  

As we added the regularization term {%raw%} $\frac{\lambda}{2m} \sum_{j=1}^{n}\theta_j^2 ${% endraw %}. We wanted to make our hypothesis function simpler to **prevent** overfitting. Therefore, we need to cancel out some high order-polynomial terms so that the function will become simpler. To make that happened, we tried to **minmize** the $\theta$ values by adding this regularzation terms within the **cost function**. And after we doing the **derivative** **of the cost function** will likey not choosing the larger $\theta$ values, it will likely choose the **smallest possble** $\theta$ values.  


#### Gradient Descent
![](http://7xihzu.com1.z0.glb.clouddn.com/20160703/logistic-regression-gradient-descent.png)
- same update rule for logistic regression compare to linear regression  
- however, **different** **hypothesis** **function** was applied.  

#### Advanced optimization with regularization  
![](http://7xihzu.com1.z0.glb.clouddn.com/20160703/advanced-optimzation-regularization.png)  

**gradient Descent vs Advanced optimization:**  
it allow us to use gradient descent algorithm BUT **no** need to **maually** pick $\alpha$ values. The computer automatically pick the best $\alpha$ value for us.  

**gradient Descent vs normal equation:**  
it gives us different algorithm to compute $\theta$ values.  



# Logs
- 06/19/2016: Complete week 1 notes and quizs  
- 06/21/2016: week 1 linear algrba review completed
- 06/27/2016: week 2 notes updated
- 06/27/2016: updated week 2: added notes for feature scaling & mean normalization.  
- 06/28/2016: week 3 started: logistic regression, decision boundary  
- 07/01/2016: week 3 lesson 2: Logistic Regression Model & advanced optimazation models  
- 07/03/2016: week 3 lesson 3: multi-classification, overfitting, regularization  



# Reference

[Front cover from Coursera](https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera.s3.amazonaws.com/topics/ml/large-icon.png)  
